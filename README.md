# Pogadane

<p align="center">
  <img src="https://repository-images.githubusercontent.com/966910196/a983cd9b-5685-4635-a5b4-7ebeaef27d50" alt="Logo Pogadane" width="600"/>
</p>

Aplikacja do generowania streszczeÅ„ z nagraÅ„ audio (np. spotkaÅ„ Teams, podcastÃ³w) lub filmÃ³w na YouTube. DziaÅ‚a lokalnie (offline) dziÄ™ki modelom GGUF i Faster-Whisper, co zapewnia bezpieczeÅ„stwo danych. UmoÅ¼liwia szybkie uzyskanie najwaÅ¼niejszych informacji z dÅ‚ugich materiaÅ‚Ã³w.

Wersja **v0.1.8** wprowadza:
- ğŸš€ Nowoczesny interfejs Material 3 (Flet)
- ğŸ§  Lokalne modele GGUF (llama-cpp-python)
- âš¡ 4x szybszÄ… transkrypcjÄ™ (faster-whisper jako biblioteka Python)
- ğŸ“¦ UproszczonÄ… instalacjÄ™ przez `install.py`
- ğŸŒ OpcjonalnÄ… integracjÄ™ z Google Gemini API

**Spis treÅ›ci**
1. [Architektura Systemu](#architektura-systemu)
2. [Wymagania WstÄ™pne](#wymagania-wstÄ™pne)
3. [Instalacja](#instalacja)
4. [Konfiguracja Modelu GGUF](#konfiguracja-modelu-gguf)
5. [Uruchomienie Aplikacji](#uruchomienie-aplikacji)
6. [Konfiguracja](#konfiguracja)
7. [Struktura Projektu](#struktura-projektu)
8. [RozwÃ³j (Development)](#rozwÃ³j-development)
9. [Licencja](#licencja)

---

## Architektura Systemu

```mermaid
flowchart TD
    subgraph user_input["Dane WejÅ›ciowe"]
        direction LR
        audio_files["ğŸµ Pliki Audio<br/>(MP3, WAV, M4A, OGG, FLAC)"]
        video_files["ğŸ¬ Pliki Wideo<br/>(MP4, MKV, AVI, MOV, WebM)"]
        youtube_urls["ğŸŒ URL-e YouTube"]
    end

    subgraph pogadane_app["Aplikacja Pogadane"]
        direction TB
        gui["ğŸ–¥ï¸ GUI (Flet / Material 3)"]
        backend["âš™ï¸ Backend Python"]
        config_mgr["ğŸ“‹ MenedÅ¼er Konfiguracji"]
    end

    subgraph transcription["ModuÅ‚ Transkrypcji"]
        direction LR
        yt_dlp["ğŸ“¥ yt-dlp<br/>(pobieranie YouTube)"]
        faster_whisper["ğŸ¤ Faster-Whisper<br/>(biblioteka Python)"]
    end

    subgraph summarization["ModuÅ‚ PodsumowaÅ„"]
        direction LR
        gguf_local["ğŸ§  GGUF Local<br/>(llama-cpp-python)"]
        ollama_opt["ğŸ¦™ Ollama<br/>(opcjonalnie)"]
        gemini_opt["âœ¨ Google Gemini<br/>(opcjonalnie, online)"]
    end

    subgraph output["Wyniki"]
        direction LR
        transcript_out["ğŸ“ Transkrypcja"]
        summary_out["ğŸ“Š Streszczenie"]
    end

    user_input --> gui
    gui --> backend
    config_mgr <--> gui
    config_mgr <--> backend
    
    backend --> yt_dlp
    yt_dlp --> faster_whisper
    audio_files --> faster_whisper
    video_files --> faster_whisper
    
    faster_whisper --> transcript_out
    transcript_out --> summarization
    
    summarization --> gguf_local
    summarization -.-> ollama_opt
    summarization -.-> gemini_opt
    
    gguf_local --> summary_out
    ollama_opt -.-> summary_out
    gemini_opt -.-> summary_out

    style gui fill:#C8E6C9,stroke:#333,stroke-width:2px
    style backend fill:#B3E5FC,stroke:#333,stroke-width:2px
    style faster_whisper fill:#D1C4E9,stroke:#333,stroke-width:2px
    style gguf_local fill:#FFCDD2,stroke:#333,stroke-width:2px
    style ollama_opt fill:#FFE0B2,stroke:#333,stroke-width:1px,stroke-dasharray: 3
    style gemini_opt fill:#FFE0B2,stroke:#333,stroke-width:1px,stroke-dasharray: 3
    style transcript_out fill:#E1BEE7,stroke:#333,stroke-width:2px
    style summary_out fill:#A5D6A7,stroke:#333,stroke-width:2px
```

**Opis komponentÃ³w:**

| Komponent | Opis |
|-----------|------|
| **GUI (Flet)** | Nowoczesny interfejs Material 3 z obsÅ‚ugÄ… przeciÄ…gnij-i-upuÅ›Ä‡, kolejkÄ… przetwarzania i menedÅ¼erem wynikÃ³w |
| **Backend** | Logika aplikacji: orkiestracja transkrypcji i podsumowaÅ„ |
| **yt-dlp** | Pobieranie audio z YouTube (biblioteka Python) |
| **Faster-Whisper** | Szybka transkrypcja mowy (CTranslate2, 4x szybsza niÅ¼ OpenAI Whisper) |
| **GGUF Local** | Lokalne modele LLM przez llama-cpp-python (domyÅ›lnie Gemma 3 4B) |
| **Ollama** | Opcjonalny backend dla lokalnych LLM |
| **Google Gemini** | Opcjonalna integracja z chmurÄ… Google AI |

---

## Wymagania WstÄ™pne

- **Python 3.9+** (zalecany 3.11+)
- **System operacyjny**: Windows, Linux lub macOS
- **RAM**: minimum 8 GB (16 GB zalecane dla modeli GGUF)
- **Miejsce na dysku**: ~3 GB (model GGUF + zaleÅ¼noÅ›ci)

---

## Instalacja

### Krok 1: Klonowanie repozytorium

```powershell
git clone https://github.com/WSB-University-Problem-Based-Learning/pogadane.git
cd pogadane
```

### Krok 2: Utworzenie Å›rodowiska wirtualnego

```powershell
cd _app
python -m venv .venv

# Windows (PowerShell)
.\.venv\Scripts\Activate.ps1

# Windows (CMD)
.\.venv\Scripts\activate.bat

# Linux / macOS
source .venv/bin/activate
```

### Krok 3: Instalacja zaleÅ¼noÅ›ci

```powershell
python install.py
```

Skrypt `install.py` automatycznie zainstaluje:
- `flet` - framework GUI
- `yt-dlp` - pobieranie z YouTube
- `faster-whisper` - transkrypcja audio
- `llama-cpp-python` - lokalne modele GGUF
- `google-generativeai` - opcjonalna integracja z Gemini

---

## Konfiguracja Modelu GGUF

Aby uÅ¼ywaÄ‡ lokalnych podsumowaÅ„ (bez internetu), pobierz model GGUF:

1. **Pobierz model** z [HuggingFace - Gemma 3 4B GGUF](https://huggingface.co/google/gemma-3-4b-it-GGUF)
   - Zalecany plik: `gemma-3-4b-it-Q4_K_M.gguf` (~2.5 GB)

2. **UmieÅ›Ä‡ w katalogu modeli**:
   ```
   _app/dep/models/gemma-3-4b-it-Q4_K_M.gguf
   ```

3. **Gotowe!** Aplikacja automatycznie wykryje model.

> **Uwaga:** JeÅ›li korzystasz z modeli Gemma, zapoznaj siÄ™ z warunkami licencjonowania w pliku [NOTICES.md](NOTICES.md).

---

## Uruchomienie Aplikacji

### Windows (najprostszy sposÃ³b)

Kliknij dwukrotnie na jeden z plikÃ³w w katalogu gÅ‚Ã³wnym:
- `Pogadane.exe` - launcher EXE
- `Pogadane.bat` - launcher BAT

### Z linii komend

```powershell
cd _app
python -m pogadane
```

### Korzystanie z GUI

1. **Dodaj pliki** - PrzeciÄ…gnij i upuÅ›Ä‡ pliki audio/wideo lub wklej URL-e YouTube
2. **Skonfiguruj** - Opcjonalnie dostosuj ustawienia w panelu âš™ï¸ Konfiguracja
3. **PrzetwÃ³rz** - Kliknij "ğŸš€ Rozpocznij Przetwarzanie"
4. **PrzeglÄ…daj wyniki** - Transkrypcja i streszczenie pojawiÄ… siÄ™ w zakÅ‚adce ğŸ“Š Wyniki

### ObsÅ‚ugiwane formaty

| Typ | Formaty |
|-----|---------|
| **Audio** | MP3, WAV, M4A, OGG, FLAC |
| **Wideo** | MP4, MKV, AVI, MOV, WebM |
| **Online** | URL-e YouTube |

---

## Konfiguracja

Ustawienia moÅ¼na edytowaÄ‡:
- **W GUI**: ZakÅ‚adka âš™ï¸ Konfiguracja
- **RÄ™cznie**: Plik `_app/.config/config.py`

### GÅ‚Ã³wne opcje konfiguracyjne

| Opcja | DomyÅ›lnie | Opis |
|-------|-----------|------|
| `WHISPER_MODEL` | `turbo` | Model Whisper (`tiny`, `base`, `small`, `medium`, `large-v3`, `turbo`) |
| `WHISPER_LANGUAGE` | `Polish` | JÄ™zyk transkrypcji |
| `SUMMARY_PROVIDER` | `gguf` | Dostawca podsumowaÅ„ (`gguf`, `ollama`, `google`) |
| `SUMMARY_LANGUAGE` | `Polish` | JÄ™zyk podsumowania |
| `GGUF_MODEL_PATH` | `dep/models/gemma-3-4b-it-Q4_K_M.gguf` | ÅšcieÅ¼ka do modelu GGUF |
| `GGUF_GPU_LAYERS` | `0` | Liczba warstw na GPU (0 = tylko CPU) |
| `LLM_PROMPT_TEMPLATE_NAME` | `Standardowy` | Wybrany szablon promptu |

### Szablony promptÃ³w LLM

DostÄ™pne predefiniowane szablony:

| Nazwa | Zastosowanie |
|-------|--------------|
| **Standardowy** | OgÃ³lne streszczenie z kluczowymi wnioskami |
| **Elementy Akcji** | Lista zadaÅ„ do wykonania (action items) |
| **GÅ‚Ã³wne Tematy** | Wylistowanie gÅ‚Ã³wnych tematÃ³w |
| **Kluczowe Pytania** | Pytania wymagajÄ…ce dalszej analizy |
| **ELI5** | Proste wyjaÅ›nienie (Explain Like I'm 5) |

MoÅ¼esz rÃ³wnieÅ¼ zdefiniowaÄ‡ wÅ‚asny prompt w polu "WÅ‚asny prompt".

### Alternatywni dostawcy podsumowaÅ„

#### Ollama (lokalnie)

```powershell
# Zainstaluj Ollama: https://ollama.com/
ollama pull gemma3:4b
```

W konfiguracji ustaw:
- `SUMMARY_PROVIDER = "ollama"`
- `OLLAMA_MODEL = "gemma3:4b"`

#### Google Gemini (online)

1. Uzyskaj klucz API: [Google AI Studio](https://aistudio.google.com/)
2. W konfiguracji ustaw:
   - `SUMMARY_PROVIDER = "google"`
   - `GOOGLE_API_KEY = "twÃ³j-klucz-api"`

---

## Struktura Projektu

```
pogadane/
â”œâ”€â”€ ğŸ“„ Pogadane.bat          # Launcher Windows (BAT)
â”œâ”€â”€ ğŸ“„ Pogadane.exe          # Launcher Windows (EXE)
â”œâ”€â”€ ğŸ“„ README.md             # Ten plik
â”œâ”€â”€ ğŸ“„ LICENSE               # Licencja MIT
â”œâ”€â”€ ğŸ“„ NOTICES.md            # Informacje o licencjach third-party
â”œâ”€â”€ ğŸ“„ .gitignore
â”‚
â”œâ”€â”€ ğŸ“ _app/                 # APLIKACJA
â”‚   â”œâ”€â”€ ğŸ“ src/pogadane/     # Kod ÅºrÃ³dÅ‚owy Python
â”‚   â”‚   â”œâ”€â”€ __main__.py      # Punkt wejÅ›cia
â”‚   â”‚   â”œâ”€â”€ gui_flet.py      # Interfejs GUI (Flet)
â”‚   â”‚   â”œâ”€â”€ backend.py       # Logika przetwarzania
â”‚   â”‚   â”œâ”€â”€ llm_providers.py # Dostawcy LLM (GGUF, Ollama, Gemini)
â”‚   â”‚   â”œâ”€â”€ transcription_providers.py  # Transkrypcja (Faster-Whisper)
â”‚   â”‚   â”œâ”€â”€ config_loader.py # Åadowanie konfiguracji
â”‚   â”‚   â””â”€â”€ constants.py     # StaÅ‚e i wartoÅ›ci domyÅ›lne
â”‚   â”œâ”€â”€ ğŸ“ res/assets/       # Zasoby (ikony, animacje)
â”‚   â”œâ”€â”€ ğŸ“ dep/models/       # Modele GGUF (nie w git)
â”‚   â”œâ”€â”€ ğŸ“ .venv/            # Åšrodowisko wirtualne (nie w git)
â”‚   â”œâ”€â”€ ğŸ“ .config/          # Konfiguracja uÅ¼ytkownika
â”‚   â”œâ”€â”€ ğŸ“„ install.py        # Skrypt instalacyjny
â”‚   â””â”€â”€ ğŸ“„ pyproject.toml    # Metadane projektu
â”‚
â””â”€â”€ ğŸ“ _dev/                 # DEVELOPMENT
    â”œâ”€â”€ ğŸ“ test/             # Testy jednostkowe (pytest)
    â”œâ”€â”€ ğŸ“ doc/              # Dokumentacja dodatkowa
    â”œâ”€â”€ ğŸ“ samples/          # PrzykÅ‚adowe pliki testowe (nie w git)
    â”œâ”€â”€ ğŸ“ build/            # WyjÅ›cie PyInstaller (nie w git)
    â””â”€â”€ ğŸ“„ create_launcher.py # Generator launcherÃ³w
```

---

## RozwÃ³j (Development)

### Instalacja narzÄ™dzi deweloperskich

```powershell
cd _app
python install.py --dev
```

Zainstaluje dodatkowo: `pytest`, `pytest-cov`, `black`, `pylint`

### Uruchamianie testÃ³w

```powershell
cd ..  # wrÃ³Ä‡ do katalogu gÅ‚Ã³wnego
pytest _dev/test/ -v
```

### Formatowanie kodu

```powershell
black _app/src/pogadane/
```

### Tworzenie launczera EXE

```powershell
python _dev/create_launcher.py
```

---

## Licencja

Projekt udostÄ™pniony na licencji **MIT** - zobacz plik [LICENSE](LICENSE).

Informacje o licencjach bibliotek zewnÄ™trznych: [NOTICES.md](NOTICES.md)

---

<p align="center">
  <strong>Pogadane</strong> Â© 2024 WSB University - Problem Based Learning
</p>

