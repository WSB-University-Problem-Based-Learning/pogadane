# Pogadane

<p align="center">
  <img src="https://repository-images.githubusercontent.com/966910196/a983cd9b-5685-4635-a5b4-7ebeaef27d50" alt="Logo Pogadane" width="600"/>
  <br/>
  <strong>Transform audio recordings and YouTube videos into transcripts and AI-powered summaries</strong>
</p>

---

## âœ¨ Highlights

- ğŸ™ï¸ **Batch transcription** for local audio files and YouTube URLs
- ğŸ¤– **AI-powered summaries** using local GGUF models, Ollama, Transformers, or Google Gemini
- ğŸ–¥ï¸ **Material 3 Expressive GUI** with waveform visualization and results viewer
- âš¡ **4x faster transcription** with faster-whisper (GPU/CPU optimized)
- ğŸ§  **Efficient AI models** using GGUF quantization (e.g., Gemma 3 4B runs on 4GB RAM)
- âš™ï¸ **Easy configuration** stored in `.config/config.py` with in-app overrides
- ğŸ§° **Cross-platform** installer that prepares dependencies in one pass

---

## ğŸš€ Quick Start

```bash
# 1. Clone the project
git clone https://github.com/WSB-University-Problem-Based-Learning/pogadane.git
cd pogadane

# 2. Create virtual environment
python -m venv .venv
.\.venv\Scripts\Activate.ps1  # Windows
# source .venv/bin/activate    # macOS/Linux

# 3. Run the installer
python install.py

# 4. Launch the app
python run_gui_flet.py
# or: python -m pogadane
```

---

## ğŸ“¦ Installation

### Option 1: Guided Installer (Recommended)

```bash
python install.py
```

The installer automatically sets up:
- **faster-whisper** - 4x faster transcription with GPU support
- **llama-cpp-python** - Efficient GGUF model support
- **yt-dlp** - YouTube video/audio download

### Option 2: Manual Installation

```bash
# Install core + recommended transcription
pip install -e .
pip install faster-whisper

# Optional: Alternative backends
pip install -r requirements-whisper.txt         # OpenAI Whisper
pip install -r requirements-transformers.txt    # HuggingFace models
```

---

## ğŸ¯ Usage

### Launch the App

```bash
python run_gui_flet.py
# or
python -m pogadane
```

### Features

1. **Add Files** - Drag & drop audio/video files or paste YouTube URLs
2. **Configure** - Choose transcription engine and AI provider in Settings
3. **Process** - Click "Start Processing" to transcribe and summarize
4. **Review** - View results with speaker diarization and AI summaries

### Supported Formats

- **Audio**: MP3, WAV, M4A, OGG, FLAC, AAC
- **Video**: MP4, MKV, AVI, MOV, WebM
- **Online**: YouTube URLs (automatic download)

---

## âš™ï¸ Configuration

Settings are stored in `.config/config.py` and can be modified via the GUI Settings panel.

### Transcription Providers

| Provider | Speed | Quality | GPU Support |
|----------|-------|---------|-------------|
| **faster-whisper** | âš¡âš¡âš¡âš¡ | â­â­â­â­ | âœ… CUDA |
| **whisper** | âš¡âš¡ | â­â­â­â­ | âœ… CUDA |

### Summarization Providers

| Provider | Offline | Quality | Requirements |
|----------|---------|---------|--------------|
| **GGUF** | âœ… | â­â­â­â­ | 4GB+ RAM |
| **Transformers** | âœ… | â­â­â­ | 8GB+ RAM |
| **Ollama** | âœ… | â­â­â­â­ | Ollama server |
| **Google Gemini** | âŒ | â­â­â­â­â­ | API key |

---

## ğŸ“ Project Structure

```
pogadane/
â”œâ”€â”€ src/pogadane/         # Main application source
â”‚   â”œâ”€â”€ gui_flet.py       # Material 3 GUI
â”‚   â”œâ”€â”€ backend.py        # Processing backend
â”‚   â”œâ”€â”€ transcription_providers.py
â”‚   â””â”€â”€ llm_providers.py
â”œâ”€â”€ test/                 # Test suite
â”œâ”€â”€ doc/                  # Documentation
â”œâ”€â”€ install.py            # Guided installer
â””â”€â”€ run_gui_flet.py       # GUI launcher
```

---

## ğŸ§ª Development

```bash
# Install dev dependencies
pip install -e .[dev]

# Run tests
pytest

# Run tests with coverage
pytest --cov=src/pogadane
```

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

### Third-Party Licenses

- **Gemma models**: Subject to [Google Gemma Terms of Use](doc/gemma_terms.md)
- See [NOTICES.md](NOTICES.md) for all third-party attributions

---

## ğŸ¤ Contributing

This project was developed as part of the Problem-Based Learning program at WSB University.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

